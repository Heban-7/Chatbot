# ğŸ¤– RAG-Based AI Chatbot ğŸ”¥


A **Retrieval-Augmented Generation (RAG) AI Chatbot** that enhances responses by retrieving relevant documents from an **embedded Pinecone vector database** before generating intelligent answers using LLMs.  

## ğŸš€ Features  

âœ… **FastAPI Backend** for efficient API-based interactions  
âœ… **Pinecone Vector Database** for document retrieval  
âœ… **LangChain Integration** for structured prompt execution  
âœ… **Document Embedding & Storage** (Fetch, Process, Store)  
âœ… **Question Rewriting for Better Search Queries**  
âœ… **Hallucination & Answer Grading System**  
âœ… **Dockerized for Easy Deployment**  

---

## ğŸ“‚ Project Structure  

```plaintext
rag-chatbot/
â”‚â”€â”€ app/                           # FastAPI application
â”‚   â”œâ”€â”€ routes/                    # API routes
â”‚   â”‚   â”œâ”€â”€ rag.py                  # Main RAG API route
â”‚   â”œâ”€â”€ workflows/                  # Core RAG logic
â”‚   â”‚   â”œâ”€â”€ nodes.py                 # Document retrieval, grading, generation
â”‚   â”‚   â”œâ”€â”€ edges.py                 # Workflow decision-making
â”‚   â”‚   â”œâ”€â”€ graphs.py                # Workflow definition
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ embedding_service.py     # Pinecone embedding & storage
â”‚   â”œâ”€â”€ dtos/                         # Request & response schemas
â”‚   â”‚   â”œâ”€â”€ rag.py
â”‚   â”œâ”€â”€ agent.py                      # LLM & prompt configurations
â”‚â”€â”€ data/                              # Document storage
â”‚â”€â”€ Dockerfile                         # Docker container setup
â”‚â”€â”€ docker-compose.yml                  # Multi-container setup (API + Pinecone)
â”‚â”€â”€ requirements.txt                    # Dependencies
â”‚â”€â”€ .env.example                        # Environment variables template
â”‚â”€â”€ README.md                           # Project documentation
```

--- 

## ğŸ› ï¸ Installation & Setup
### 1ï¸âƒ£ Clone the Repository

git clone https://github.com/Heban-7/rag-chatbot.git
cd rag-chatbot

### 2ï¸âƒ£ Set Up Environment Variables

Create a .env file (or rename .env.example) and configure:

```
PINECONE_API_KEY=your_pinecone_api_key
BASE_URI=https://api.openai.com
API_KEY=your_openai_api_key
MODEL_NAME=gpt-4
INDEX_NAME=your_pinecone_index
NAMESPACE=your_pinecone_namespace
```

### 3ï¸âƒ£ Install Dependencies

```pip install -r requirements.txt```

### 4ï¸âƒ£ Start the FastAPI Server

```uvicorn app:app --host 0.0.0.0 --port 8000```

## ğŸ³ Running with Docker

```docker-compose up -d --build```
